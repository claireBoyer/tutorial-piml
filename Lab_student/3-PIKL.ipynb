{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Physics-informed kernel methods"
      ],
      "metadata": {
        "id": "_6fw7pyVIk8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1- PDE kernels"
      ],
      "metadata": {
        "id": "uRzdzXsrIopl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 - Mathematical setting"
      ],
      "metadata": {
        "id": "YY3sTlpBKBrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hybrid modelling.** Here, the goal is to implement the physics-informed kernel to learn a function $f^\\star$ such that\n",
        "* $Y = f^\\star(X) + \\varepsilon$,\n",
        "* $f^\\star$ is the solution to a PDE\n",
        "\n",
        "given i.i.d. observations $(X_1,Y_1)$, ..., $(X_n, Y_n)$."
      ],
      "metadata": {
        "id": "-goxHFscT_ui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fourier expansion.** In the last tutorial, we saw how to create Sobolev kernel on $[0, 0.5]$ by relying on the maps $\\phi_m(x) = (\\exp(-i 2 \\pi k x))_{-m \\leq k \\leq m}$. Let $m\\in \\mathbb N^\\star$ be the number of Fourier modes. Let $$H_m = \\{x\\mapsto \\sum_{k=-m}^m  \\theta_k \\exp(i 2 \\pi k x), \\quad \\theta_k \\in \\mathbb C\\} = \\{x\\mapsto \\langle \\phi(x), \\theta \\rangle, \\quad \\theta_k \\in \\mathbb C\\}$$\n",
        "be the space of complex-valued trigonometric polynomials of degree at most $m$."
      ],
      "metadata": {
        "id": "h0U9kcs8XpqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1.** Assume $d=1$, $\\Omega = [0,0.5]$. Find a matrix $C$ such that, for all function $f\\in H_m$, $$\\int_{0}^{0.5} f(x)^2dx = \\theta^* C \\theta,$$\n",
        "where $\\theta\\in \\mathbb C^{2m+1}$ is such that  $f(x) = \\langle \\phi(x), \\theta \\rangle$."
      ],
      "metadata": {
        "id": "ZkntV4bQZw8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer.**\n",
        "<details>\n",
        "  <summary>  (Click to show)</summary>\n",
        "  $$\\int_0^{0.5} |f|^2 = \\int_0^{0.5} \\bar f \\times f = \\sum_{k_1 = -m}^m \\sum_{k_2=-m}^m \\bar \\theta_{k_1} \\theta_{k_2}\\int_{0}^{0.5} \\exp(i 2\\pi (k_2-k_1) x)dx .$$\n",
        "  Thus, the matrix $C$ is such that $C_{k_1, k_2} = \\int_{0}^{0.5} \\exp(i 2\\pi (k_2-k_1) x)dx$.\n",
        "  $$\\int_{0}^{0.5} \\exp(i 2\\pi (k_2-k_1) x)dx = \\frac{\\exp(i \\pi (k_2-k_1)) - 1}{i 2 \\pi (k_2-k_1)} = \\exp(i \\pi (k_2-k_1)/2)\\frac{\\sin(\\pi (k_2-k_1)/2)}{\\pi (k_2-k_1)}.$$\n",
        "  Thus, $C$ is a $(2m+1) \\times (2m+1)$ complex-valued matrix such that\n",
        "  $$C_{k_1, k_2} = \\exp(i \\pi (k_2-k_1)/2)\\frac{\\sin(\\pi (k_2-k_1)/2)}{\\pi (k_2-k_1)}.$$\n",
        "\n",
        "  If $k_1=k_2$, then $C_{k_1, k_2} = 1/2$.\n",
        "</details>"
      ],
      "metadata": {
        "id": "XsTokck-YjIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2.** Consider the ODE $f'+f = 0$. Find a matrix $M$ such that, for all function $f\\in H_m$\n",
        "$$\\int_{0}^{0.5} (f'(x)+f(x))^2dx = \\theta^* M \\theta,$$\n",
        "where $\\theta\\in \\mathbb C^{2m+1}$ is such that  $f(x) = \\langle \\phi(x), \\theta \\rangle$."
      ],
      "metadata": {
        "id": "ZgzGvIaGHIsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer.**\n",
        "<details>\n",
        "  <summary>  (Click to show)</summary>\n",
        "  We have that $$f'(x) = \\sum_{k=-m}^m  \\theta_k i 2\\pi k \\exp(i 2 \\pi k x).$$\n",
        "  Thus, the Fourier coefficient of $f'$ is $D\\theta$, where $D$ is the diagonal matrix such that $D_{k,k} =  i 2\\pi k$.\n",
        "  Hence, $(D+I)\\theta$ is the Fourier coefficient of $f'+f$.\n",
        "  Finally, we deduce that $M = (D+I)^* C (D+I)$.  \n",
        "</details>"
      ],
      "metadata": {
        "id": "ySXh7_7FJdp2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3.** Find the minimizer of the empirical risk\n",
        "$$L(f) = \\frac{1}{n}\\sum_{j=1}^n (f(X_i)-Y_i)^2 + \\lambda \\int_0^{0.5}(f'(x)+f(x))^2dx + \\mu \\|f\\|_{H^1}^2$$\n",
        "over the space $H_m$, where $\\|f\\|_{H^2}^2 = \\sum_{k=-m}^m|\\theta_k|^2(1+k^2)$."
      ],
      "metadata": {
        "id": "2mgrZg90OZJN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer.**\n",
        "<details>\n",
        "  <summary>  (Click to show)</summary>\n",
        "  The risk can be expressed in terms of $\\theta$ as\n",
        "  $$R(\\theta) = \\frac{1}{n}\\|\\Phi \\theta - \\mathbb Y\\|_2^2 + \\lambda \\theta^* M \\theta + \\mu \\theta^* S \\theta,$$\n",
        "  where\n",
        "\n",
        "  * $\\Phi = \\begin{pmatrix}\\phi(X_1)^*\\\\\\vdots\\\\\\phi(X_n)^*\\end{pmatrix},$\n",
        "  * $S$ is the diagonal matrix such that $S_{k,k} = (1+k^4)$,\n",
        "  * $\\mathbb Y = \\begin{pmatrix}Y_1\\\\\\vdots\\\\Y_n\\end{pmatrix}$.\n",
        "\n",
        "  $R$ is differentiable, the minimizer of $R$ is obtained by solving $dR(\\hat \\theta) = 0$. This results in\n",
        "  $$\\hat \\theta = (n^{-1} \\Phi^* \\Phi + \\lambda M + \\mu S)^{-1} \\Phi^* \\mathbb Y.$$\n",
        "  Therefore, the minimizer of $L$ is $\\hat f$ defined by $\\hat f(x) = \\langle \\phi(x), \\theta\\rangle$.\n",
        "</details>"
      ],
      "metadata": {
        "id": "jmiXcunvO8n9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 - Implementing the kernel"
      ],
      "metadata": {
        "id": "3W4C1i8wXkHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "LUs4uNyvkr7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4.** Create a function *C_matrix* taking as inputs m and the device, and returning the matrix C."
      ],
      "metadata": {
        "id": "3QAXnWoaVJMi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHilzohjITHR"
      },
      "outputs": [],
      "source": [
        "def C_matrix(m, device):\n",
        "  #TO DO\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5.** Create a function *M_matrix* taking as inputs m and the device, and returning the matrix $M$."
      ],
      "metadata": {
        "id": "zd7ciEUzmYRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def D_matrix(m, device):\n",
        "  #TO D0\n",
        "\n",
        "  return\n",
        "\n",
        "def dagger(matrix):\n",
        "  return matrix.conj().T\n",
        "\n",
        "def M_matrix(m, device):\n",
        "  #TO DO\n",
        "  return"
      ],
      "metadata": {
        "id": "E_CrJOtUmdno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7.** Create a function *S_matrix* taking as inputs m and the device, and returning the matrix $S$."
      ],
      "metadata": {
        "id": "_lwNzFRgqqXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def S_matrix(m, device):\n",
        "  #TO DO\n",
        "  return"
      ],
      "metadata": {
        "id": "X5sxGRubqztL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 8.** Create a function *phi_matrix* taking as inputs m and the device, and returning the matrix $\\Phi$."
      ],
      "metadata": {
        "id": "hKZOK8vDruBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def phi_matrix(x, m):\n",
        "  #TO DO\n",
        "  return"
      ],
      "metadata": {
        "id": "_gyzP4kTrs3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 9.** Implement a function *generate_data* taking as inputs\n",
        "\n",
        "* the number $n$ of training points,\n",
        "* the standard deviation $\\sigma$ of the noise\n",
        "\n",
        "and returns as outputs\n",
        "\n",
        "* a tensor of shape (n) encoding the features $(X_1, \\dots, X_n)$\n",
        "* a tensor of shape (n,1) encoding the features $(Y_1, \\dots, Y_n)$ such that $Y_i = f^\\star(X_i)+\\sigma N(0,1)$.\n",
        "\n",
        "In this example, sample $X_i$ uniformely on $[0, 0.5]$ and take $f^\\star(x) = 2\\exp(-x)$ is a solution of the ODE $f'+f = 0$."
      ],
      "metadata": {
        "id": "bwwx1wzFnaw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data(n, sigma, device):\n",
        "  #TO DO\n",
        "  return"
      ],
      "metadata": {
        "id": "fr2TfDk8oqCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10.** Implement a function *hat_theta* taking as inputs\n",
        "\n",
        "* the hyperparameters $\\lambda$ and $\\mu$,\n",
        "* the maximum frequency $m$ of the Fourier modes,\n",
        "* the training feature vector $x$,\n",
        "* the training target vector $y$,\n",
        "\n",
        "and returns the vector $\\hat \\theta$."
      ],
      "metadata": {
        "id": "_k5KK7Epo9rS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hat_theta(lamb, mu, m, x, y, device):\n",
        "  # TO DO\n",
        "  return"
      ],
      "metadata": {
        "id": "-PIewJPgqQAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 11.** Evaluate the performance of the kernel method with $n = 10$ with physics ($\\lambda = 1$) and without physics ($\\lambda = 0$). Set $m=100$, $\\sigma = 0.1$, and $\\mu = 10^{-2}$."
      ],
      "metadata": {
        "id": "a4BMOyYcuuTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = 100\n",
        "n = 10\n",
        "sigma = 0.1\n",
        "mu = 10**-2\n",
        "\n",
        "# Training data generation\n",
        "torch.manual_seed(1)\n",
        "x_train, y_train = generate_data(n, sigma, device)\n",
        "\n",
        "# Training models\n",
        "theta_piml = ...\n",
        "theta_data_driven = ...\n",
        "\n",
        "# Test data generation\n",
        "x_test = ...\n",
        "ground_truth = ...\n",
        "\n",
        "# MSE\n",
        "phi_test = ...\n",
        "\n",
        "y_data_driven = ...\n",
        "y_piml = ...\n",
        "\n",
        "mse_data_driven = torch.mean((y_data_driven - ground_truth)**2).item()\n",
        "mse_piml = torch.mean((y_piml - ground_truth)**2).item()\n",
        "\n",
        "print(\"MSE without physics \", mse_data_driven)\n",
        "print(\"MSE with physics \", mse_piml)"
      ],
      "metadata": {
        "id": "xpdGbBgnvDuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a figure with 2 subplots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# --- Subplot 1: Training Data\n",
        "axs[0].plot(x_test, y_data_driven, label=\"Without physics\")\n",
        "axs[0].plot(x_test, ground_truth, label=\"Ground truth\", linestyle = \"--\")\n",
        "axs[0].scatter(x_train, y_train, label=\"Training data\", color = \"green\")\n",
        "axs[0].set_xlabel(\"X\")\n",
        "axs[0].set_ylabel(\"Y\")\n",
        "axs[0].legend()\n",
        "axs[0].set_title(\"Without physics\")\n",
        "\n",
        "# --- Subplot 1: Training Data\n",
        "axs[1].plot(x_test, y_piml, label=\"With physics\")\n",
        "axs[1].plot(x_test, ground_truth, label=\"Ground truth\", linestyle = \"--\")\n",
        "axs[1].scatter(x_train, y_train, label=\"Training data\", color = \"green\")\n",
        "axs[1].set_xlabel(\"X\")\n",
        "axs[1].set_ylabel(\"Y\")\n",
        "axs[1].legend()\n",
        "axs[1].set_title(\"With physics\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GV8nsJTbxmP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2- Pikernel package\n"
      ],
      "metadata": {
        "id": "Sn5KcXueJ08S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Downloading the package"
      ],
      "metadata": {
        "id": "ZDOBJe6odcC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *pikernel* package implements an optimized version of the algorithm from the papers\n",
        "\n",
        "* *Physics-informed machine learning as a kernel method*, COLT (2024)\n",
        "* *Physics-informed kernel learning*, In review (2024)."
      ],
      "metadata": {
        "id": "U7S5eA87Xq50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 12.** Install the package by running the following command. Go to the pip repository [https://pypi.org/project/pikernel/](https://pypi.org/project/pikernel/) and read the minimal examples in dimension 1 and 2."
      ],
      "metadata": {
        "id": "Sb_xtJ7NYKHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pikernel"
      ],
      "metadata": {
        "id": "RcqMnMHcJ9d-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "82be9091-1f9f-4769-a496-e2010e3613c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pikernel in /usr/local/lib/python3.11/dist-packages (0.0.8)\n",
            "Requirement already satisfied: matplotlib>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from pikernel) (3.10.0)\n",
            "Requirement already satisfied: numpy>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pikernel) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.2.2 in /usr/local/lib/python3.11/dist-packages (from pikernel) (2.2.2)\n",
            "Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from pikernel) (2.6.0+cu124)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.9.0->pikernel) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.9.0->pikernel) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.9.0->pikernel) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.9.0->pikernel) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.9.0->pikernel) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.9.0->pikernel) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.9.0->pikernel) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.9.0->pikernel) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.2->pikernel) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.2->pikernel) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->pikernel) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.6.0->pikernel) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.9.0->pikernel) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.6.0->pikernel) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 ODE with a driving term"
      ],
      "metadata": {
        "id": "0aKQKA_-dhFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 13.** Using the *pikernel* package, how would you design an algorithm taking into account the ODE a priori $$f'(x) + f(x) = x^2?$$"
      ],
      "metadata": {
        "id": "-I8-lVKSYnKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer.**\n",
        "<details>\n",
        "  <summary>  (Click to show)</summary>\n",
        "\n",
        "  **Superposition principle.** The superposition principle states that $f$ is a solution to the ODE $f'(x) + f(x) = x^2$ if and only if\n",
        "\n",
        "  * $f - g$ is a solution to the homogeneous ODE $(f-g)'(x) + (f-g)(x) = 0$,\n",
        "  * where $g$ is a particular solution to the ODE $g'(x) + g(x) = x^2$.\n",
        "\n",
        "  We look for a solution $g$ of the form $g(x) =  bx^2 +cx + d$. The ODE $g'(x) + g(x) = x^2$ implies that\n",
        "\n",
        "  * b = 1\n",
        "  * 2b + c = 0\n",
        "  * c + d = 0.\n",
        "\n",
        "\n",
        "  Thus, $c = -d$, $b = 1 = -c/2 = d/2$, leading to $g(x) = x^2 -2x + 2$.\n",
        "\n",
        "  **Conclusion.** Thus, we know that $f^\\star - g$ is a solution to the homogeneous ODE $(f-g)'(x) + (f-g)(x) = 0$. We only need to learn $f^\\star - g$ from the data $(X_1, Y_1 - g(X_1)), \\dots, (X_n, Y_n - g(X_n))$.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "6Nv2hDtyZGs7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 14.** Implement this algorithm with\n",
        "* $f^\\star(x) = \\exp(-x) + x^2 - 2x +2$,\n",
        "* $X$ following the uniform distribution on $[-1, 1]$,  \n",
        "* $\\varepsilon$ being a gaussian noise of distribution $ N(0,1)$,\n",
        "* $n = 10^3$, $\\lambda_n = 1/n$, and $\\mu_n = 1$,\n",
        "* $s = 3$,\n",
        "* $m = 10^2$ Fourier modes."
      ],
      "metadata": {
        "id": "sYhpPPd3blYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO"
      ],
      "metadata": {
        "id": "UWd-s1slcDLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Extrapolation using a PDE with a driving term"
      ],
      "metadata": {
        "id": "ShaEQLIeevxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 15.** How would you use the *pikernel* package to learn the a function satisfying the Poisson PDE $$\\partial_1^2 f(x_1, x_2) + \\partial_2^2 f(x_1, x_2) = \\cos(x_1)?$$"
      ],
      "metadata": {
        "id": "PqOtrPGfez1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer.**\n",
        "<details>\n",
        "  <summary>  (Click to show)</summary>\n",
        "\n",
        "  **Superposition principle.** The superposition principle states that $f$ is a solution to the ODE $\\partial_1^2 f(x_1, x_2) + \\partial_2^2 f(x_1, x_2) = \\cos(x_1)$ if and only if\n",
        "\n",
        "  * $f - g$ is a solution to the homogeneous ODE $\\partial_1^2 (f-g) + \\partial_2^2 (f-g) = 0$,\n",
        "  * where $g$ is a particular solution to the ODE $\\partial_1^2 g(x_1, x_2) + \\partial_2^2 g(x_1, x_2) = \\cos(x_1)$.\n",
        "\n",
        "\n",
        "  The function $g(x_1, x_2) =  -\\cos(x_1)$ works.\n",
        "\n",
        "\n",
        "  **Conclusion.** Thus, we know that $f^\\star - g$ is a solution to the Laplace equation  $\\partial_1^2 (f-g) + \\partial_2^2 (f-g) = 0 = 0$. We only need to learn $f^\\star - g$ from the data $(X_1, Y_1 - g(X_1)), \\dots, (X_n, Y_n - g(X_n))$.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "3jLc_9LcfWph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 16.** Implement this algorithm with\n",
        "* $f^\\star(x_1, x_2) = 1-x_1+x_2-\\cos(x_1)$,\n",
        "* $X_1$ and $X_2$ being independent and following the uniform distribution on $[-0.5, 0.5]$,  \n",
        "* $\\varepsilon$ being a gaussian noise of distribution $ N(0,1)$,\n",
        "* $n = 10^3$, $\\lambda_n = n^{-2/3}$, and $\\mu_n = 1$,\n",
        "* $s = 2$,\n",
        "* $m = 10$ Fourier modes.\n",
        "\n",
        "Though the training data are sampled in $[0.5, 0.5]^2$, we assume that the PDE is satified over the whole disk $D = \\{x_1^2 + x_2^2 \\leq 1\\}$.\n",
        "Evaluate the performance of the kernel method in extrapolation on $D$, by computing its MSE on with $X_1^{(test)}$ and $X_2^{(test)}$ sampled on $D$. Take $(X_1^{(test)},\\; X_2^{(test)}) = (R\\cos(\\theta),\\; R\\sin(\\theta))$ such that  $R$ follows the uniform distribution on $[0,1]$ and $\\theta$ follows the uniform distribution on $[0,2\\pi]$.\n",
        "\n",
        "Compare the performance of the Physics-informed kernel ($\\mu_n = 1$) and the Sobolev kernel ($\\mu_n = 0$)."
      ],
      "metadata": {
        "id": "S_BIBOAJgKOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO"
      ],
      "metadata": {
        "id": "PGCEYf-MgHgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The physics-informed kernel clearly extrapolates way better than the Sobolev kernel."
      ],
      "metadata": {
        "id": "UCdUxKPlqqDO"
      }
    }
  ]
}